{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# 8th July, 2019\n",
    "#Author Esha Sarkar\n",
    "import pandas\n",
    "import numpy as np\n",
    "import keras\n",
    "\n",
    "from random import seed\n",
    "from random import randint\n",
    "from numpy import array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras import optimizers\n",
    "from random import seed\n",
    "from random import randint\n",
    "from numpy import array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import LSTM,Dropout,Reshape\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TagGenotypes_10k = np.array(pandas.read_csv('sorted_tag_SNPs_10k_genotypes.txt', sep='\\s+', delimiter=None, header=None, names=None, index_col=None))\n",
    "TargetGenotypes = np.array(pandas.read_csv('sorted_target_SNP_genotypes.txt', sep='\\s+', delimiter=None, header=None, names=None, index_col=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DatasetX1_10k = TagGenotypes_10k[:,4:].transpose()\n",
    "DatasetY1_10k = TargetGenotypes[:,4:].transpose()\n",
    "ShufflingVector_10k = np.random.permutation(DatasetX1_10k.shape[0])\n",
    "DatasetX_10k = DatasetX1_10k[ShufflingVector_10k]\n",
    "DatasetY_10k = DatasetY1_10k[ShufflingVector_10k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OneHotEncoder(Matrix):\n",
    "    Temp = np.zeros((Matrix.shape[0],Matrix.shape[1],3))\n",
    "    for num, i in enumerate(Matrix):\n",
    "        Temp[num] = (tf.keras.utils.to_categorical(i,3))\n",
    "    return (Temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(0.8*(DatasetX_10k.shape[0]))\n",
    "Xtr1_10k = DatasetX_10k[:split]\n",
    "Xtr_10k = (OneHotEncoder(Xtr1_10k)).reshape((Xtr1_10k.shape[0],Xtr1_10k.shape[1]*3))\n",
    "\n",
    "Xts1_10k = DatasetX_10k[split:]\n",
    "Xts_10k = (OneHotEncoder(Xts1_10k)).reshape((Xts1_10k.shape[0],Xts1_10k.shape[1]*3))\n",
    "\n",
    "ytr1_10k = DatasetY_10k[:split]\n",
    "ytr_10k = (OneHotEncoder(ytr1_10k)).reshape((ytr1_10k.shape[0],ytr1_10k.shape[1]*3))\n",
    "\n",
    "yts1_10k = DatasetY_10k[split:]\n",
    "yts_10k = (OneHotEncoder(yts1_10k)).reshape((yts1_10k.shape[0],yts1_10k.shape[1]*3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('XTrain_10k.txt', Xtr1_10k, delimiter=',',fmt='%1d') \n",
    "np.savetxt('XTest_10k.txt', Xts1_10k, delimiter=',',fmt='%1d') \n",
    "np.savetxt('YTrain_10k.txt', ytr1_10k, delimiter=',',fmt='%1d') \n",
    "np.savetxt('YTest_10k.txt', yts1_10k, delimiter=',',fmt='%1d') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Accuracy(X,y,ModelName):\n",
    "    y_actual = np.argmax(y.reshape((y.shape[0],int(y.shape[1]/3),3)),2)\n",
    "    y1 = (ModelName.predict(X))\n",
    "    y_hat = np.argmax((y1.reshape((y1.shape[0],int(y1.shape[1]/3),3))),2)\n",
    "    A = (np.count_nonzero(y_hat==y_actual))/(y_actual.shape[0]*y_actual.shape[1])\n",
    "    return (A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\es4211\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1500)              4704000   \n",
      "=================================================================\n",
      "Total params: 4,704,000\n",
      "Trainable params: 4,704,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "TagNos = DatasetX_10k.shape[1]\n",
    "from keras.constraints import maxnorm, nonneg\n",
    "from keras import backend as K\n",
    "K.clear_session()\n",
    "model_10k = Sequential()\n",
    "model_10k.add(Dense(1500, input_dim=TagNos*3,bias_constraint=keras.constraints.NonNeg(),kernel_constraint=keras.constraints.NonNeg()))\n",
    "opt = keras.optimizers.Adam(lr=0.0008, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model_10k.compile(loss='mean_squared_error', optimizer=opt)\n",
    "model_10k.summary()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================================\n",
      "KFOLD:  0\n",
      "Test: 0 400\n",
      "Train: [ 0 0 ] [ 400 2003 ]\n",
      "WARNING:tensorflow:From c:\\users\\es4211\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/30\n",
      "1603/1603 [==============================] - 10s 6ms/step - loss: 18.8468\n",
      "Epoch 2/30\n",
      "1603/1603 [==============================] - 8s 5ms/step - loss: 0.1140\n",
      "Epoch 3/30\n",
      "1603/1603 [==============================] - 8s 5ms/step - loss: 0.0455\n",
      "Epoch 4/30\n",
      "1603/1603 [==============================] - 9s 5ms/step - loss: 0.0410\n",
      "Epoch 5/30\n",
      "1603/1603 [==============================] - 9s 5ms/step - loss: 0.0385\n",
      "Epoch 6/30\n",
      "1603/1603 [==============================] - 9s 5ms/step - loss: 0.0364\n",
      "Epoch 7/30\n",
      "1603/1603 [==============================] - 9s 6ms/step - loss: 0.0346\n",
      "Epoch 8/30\n",
      "1603/1603 [==============================] - 8s 5ms/step - loss: 0.0330\n",
      "Epoch 9/30\n",
      "1603/1603 [==============================] - 8s 5ms/step - loss: 0.0315\n",
      "Epoch 10/30\n",
      "1603/1603 [==============================] - 8s 5ms/step - loss: 0.0302\n",
      "Epoch 11/30\n",
      "1603/1603 [==============================] - 8s 5ms/step - loss: 0.0290\n",
      "Epoch 12/30\n",
      "1603/1603 [==============================] - 9s 5ms/step - loss: 0.0279\n",
      "Epoch 13/30\n",
      "1603/1603 [==============================] - 9s 6ms/step - loss: 0.0269\n",
      "Epoch 14/30\n",
      "1603/1603 [==============================] - 9s 5ms/step - loss: 0.0260\n",
      "Epoch 15/30\n",
      "1603/1603 [==============================] - 9s 6ms/step - loss: 0.0252\n",
      "Epoch 16/30\n",
      "1603/1603 [==============================] - 9s 6ms/step - loss: 0.0245\n",
      "Epoch 17/30\n",
      "1603/1603 [==============================] - 9s 5ms/step - loss: 0.0238\n",
      "Epoch 18/30\n",
      "1603/1603 [==============================] - 8s 5ms/step - loss: 0.0232\n",
      "Epoch 19/30\n",
      "1603/1603 [==============================] - 9s 6ms/step - loss: 0.0226\n",
      "Epoch 20/30\n",
      "1603/1603 [==============================] - 10s 6ms/step - loss: 0.0221\n",
      "Epoch 21/30\n",
      "1603/1603 [==============================] - 10s 6ms/step - loss: 0.0217\n",
      "Epoch 22/30\n",
      "1603/1603 [==============================] - 9s 5ms/step - loss: 0.0213\n",
      "Epoch 23/30\n",
      "1603/1603 [==============================] - 8s 5ms/step - loss: 0.0209\n",
      "Epoch 24/30\n",
      "1603/1603 [==============================] - 8s 5ms/step - loss: 0.0205\n",
      "Epoch 25/30\n",
      "1603/1603 [==============================] - 9s 5ms/step - loss: 0.0202\n",
      "Epoch 26/30\n",
      "1603/1603 [==============================] - 9s 6ms/step - loss: 0.0199\n",
      "Epoch 27/30\n",
      "1603/1603 [==============================] - 9s 6ms/step - loss: 0.0196\n",
      "Epoch 28/30\n",
      "1603/1603 [==============================] - 9s 6ms/step - loss: 0.0194\n",
      "Epoch 29/30\n",
      "1603/1603 [==============================] - 9s 6ms/step - loss: 0.0191\n",
      "Epoch 30/30\n",
      "1603/1603 [==============================] - 8s 5ms/step - loss: 0.0189\n",
      "Training accuracy:  0.8811228945726762\n",
      "Test:  0.83347\n",
      "========================================================================================================\n",
      "========================================================================================================\n",
      "KFOLD:  1\n",
      "Test: 400 800\n",
      "Train: [ 0 400 ] [ 800 2003 ]\n",
      "Epoch 1/30\n",
      "1603/1603 [==============================] - 9s 6ms/step - loss: 0.0196\n",
      "Epoch 2/30\n",
      "1603/1603 [==============================] - 8s 5ms/step - loss: 0.0193\n",
      "Epoch 3/30\n",
      "1603/1603 [==============================] - 8s 5ms/step - loss: 0.0190\n",
      "Epoch 4/30\n",
      "1603/1603 [==============================] - 9s 6ms/step - loss: 0.0187\n",
      "Epoch 5/30\n",
      "1603/1603 [==============================] - 9s 5ms/step - loss: 0.0184\n",
      "Epoch 6/30\n",
      "1603/1603 [==============================] - 9s 5ms/step - loss: 0.0182\n",
      "Epoch 7/30\n",
      "1603/1603 [==============================] - 9s 6ms/step - loss: 0.0180\n",
      "Epoch 8/30\n",
      "1603/1603 [==============================] - 9s 5ms/step - loss: 0.0178\n",
      "Epoch 9/30\n",
      "1603/1603 [==============================] - 9s 5ms/step - loss: 0.0177\n",
      "Epoch 10/30\n",
      "1603/1603 [==============================] - 9s 5ms/step - loss: 0.0175\n",
      "Epoch 11/30\n",
      "1603/1603 [==============================] - 9s 6ms/step - loss: 0.0174A: 2s\n",
      "Epoch 12/30\n",
      "1603/1603 [==============================] - 9s 6ms/step - loss: 0.0173\n",
      "Epoch 13/30\n",
      "1603/1603 [==============================] - 9s 6ms/step - loss: 0.0172\n",
      "Epoch 14/30\n",
      "1603/1603 [==============================] - 9s 6ms/step - loss: 0.0170 ETA:\n",
      "Epoch 15/30\n",
      "1603/1603 [==============================] - 9s 6ms/step - loss: 0.0170\n",
      "Epoch 16/30\n",
      "1603/1603 [==============================] - 9s 5ms/step - loss: 0.0169A: 2\n",
      "Epoch 17/30\n",
      "1603/1603 [==============================] - 9s 6ms/step - loss: 0.0168\n",
      "Epoch 18/30\n",
      "1603/1603 [==============================] - 9s 6ms/step - loss: 0.0168\n",
      "Epoch 19/30\n",
      "1603/1603 [==============================] - 9s 6ms/step - loss: 0.0167\n",
      "Epoch 20/30\n",
      "1603/1603 [==============================] - 9s 5ms/step - loss: 0.0166\n",
      "Epoch 21/30\n",
      "1603/1603 [==============================] - 9s 5ms/step - loss: 0.0165\n",
      "Epoch 22/30\n",
      "1603/1603 [==============================] - 9s 6ms/step - loss: 0.0165\n",
      "Epoch 23/30\n",
      "1603/1603 [==============================] - 8s 5ms/step - loss: 0.0165\n",
      "Epoch 24/30\n",
      "1603/1603 [==============================] - 8s 5ms/step - loss: 0.0164\n",
      "Epoch 25/30\n",
      "1603/1603 [==============================] - 8s 5ms/step - loss: 0.0164\n",
      "Epoch 26/30\n",
      "1603/1603 [==============================] - 8s 5ms/step - loss: 0.0163\n",
      "Epoch 27/30\n",
      "1603/1603 [==============================] - 8s 5ms/step - loss: 0.0163\n",
      "Epoch 28/30\n",
      "1603/1603 [==============================] - 8s 5ms/step - loss: 0.0163A: 1s - \n",
      "Epoch 29/30\n",
      "1603/1603 [==============================] - 9s 5ms/step - loss: 0.0162\n",
      "Epoch 30/30\n",
      "1603/1603 [==============================] - 8s 5ms/step - loss: 0.0162\n",
      "Training accuracy:  0.8862245789145352\n",
      "Test:  0.84683\n",
      "========================================================================================================\n",
      "========================================================================================================\n",
      "KFOLD:  2\n",
      "Test: 800 1200\n",
      "Train: [ 0 800 ] [ 1200 2003 ]\n",
      "Epoch 1/30\n",
      "1603/1603 [==============================] - 8s 5ms/step - loss: 0.0169\n",
      "Epoch 2/30\n",
      "1603/1603 [==============================] - 8s 5ms/step - loss: 0.0168\n",
      "Epoch 3/30\n",
      "1603/1603 [==============================] - 8s 5ms/step - loss: 0.0167\n",
      "Epoch 4/30\n",
      "1603/1603 [==============================] - 8s 5ms/step - loss: 0.0166\n",
      "Epoch 5/30\n",
      "1603/1603 [==============================] - 8s 5ms/step - loss: 0.0165\n",
      "Epoch 6/30\n",
      "1603/1603 [==============================] - 8s 5ms/step - loss: 0.0165\n",
      "Epoch 7/30\n",
      "1603/1603 [==============================] - 9s 5ms/step - loss: 0.0164A: 0s - loss: 0\n",
      "Epoch 8/30\n",
      "1603/1603 [==============================] - 8s 5ms/step - loss: 0.0163\n",
      "Epoch 9/30\n",
      "1603/1603 [==============================] - 8s 5ms/step - loss: 0.0163\n",
      "Epoch 10/30\n",
      "1603/1603 [==============================] - 8s 5ms/step - loss: 0.0162\n",
      "Epoch 11/30\n",
      "1603/1603 [==============================] - 9s 5ms/step - loss: 0.0162\n",
      "Epoch 12/30\n",
      "1603/1603 [==============================] - 9s 6ms/step - loss: 0.0162\n",
      "Epoch 13/30\n",
      "1603/1603 [==============================] - 8s 5ms/step - loss: 0.0161\n",
      "Epoch 14/30\n",
      "1603/1603 [==============================] - 8s 5ms/step - loss: 0.0161\n",
      "Epoch 15/30\n",
      "1603/1603 [==============================] - 8s 5ms/step - loss: 0.0161\n",
      "Epoch 16/30\n",
      "1603/1603 [==============================] - 8s 5ms/step - loss: 0.0160\n",
      "Epoch 17/30\n",
      "1603/1603 [==============================] - 8s 5ms/step - loss: 0.0159\n",
      "Epoch 18/30\n",
      "1603/1603 [==============================] - 9s 6ms/step - loss: 0.0159\n",
      "Epoch 19/30\n",
      "1603/1603 [==============================] - 9s 6ms/step - loss: 0.0159\n",
      "Epoch 20/30\n",
      "1603/1603 [==============================] - 8s 5ms/step - loss: 0.0158\n",
      "Epoch 21/30\n",
      "1603/1603 [==============================] - 9s 5ms/step - loss: 0.0158\n",
      "Epoch 22/30\n",
      "1603/1603 [==============================] - 8s 5ms/step - loss: 0.0157\n",
      "Epoch 23/30\n",
      "1603/1603 [==============================] - 9s 6ms/step - loss: 0.0157\n",
      "Epoch 24/30\n",
      "1603/1603 [==============================] - 9s 6ms/step - loss: 0.0157\n",
      "Epoch 25/30\n",
      "1603/1603 [==============================] - 9s 6ms/step - loss: 0.0157\n",
      "Epoch 26/30\n",
      "1603/1603 [==============================] - 9s 6ms/step - loss: 0.0157\n",
      "Epoch 27/30\n",
      "1603/1603 [==============================] - 9s 5ms/step - loss: 0.0156\n",
      "Epoch 28/30\n",
      "1603/1603 [==============================] - 9s 6ms/step - loss: 0.0156\n",
      "Epoch 29/30\n",
      "1603/1603 [==============================] - 9s 6ms/step - loss: 0.0156\n",
      "Epoch 30/30\n",
      "1603/1603 [==============================] - 9s 6ms/step - loss: 0.0156\n",
      "Training accuracy:  0.8870155957579539\n",
      "Test:  0.86015\n",
      "========================================================================================================\n",
      "========================================================================================================\n",
      "KFOLD:  3\n",
      "Test: 1200 1600\n",
      "Train: [ 0 1200 ] [ 1600 2003 ]\n",
      "Epoch 1/30\n",
      "1603/1603 [==============================] - 9s 6ms/step - loss: 0.0163\n",
      "Epoch 2/30\n",
      "1603/1603 [==============================] - 9s 5ms/step - loss: 0.0163\n",
      "Epoch 3/30\n",
      "1603/1603 [==============================] - 9s 6ms/step - loss: 0.0162A: 1s - loss:\n",
      "Epoch 4/30\n",
      "1603/1603 [==============================] - 8s 5ms/step - loss: 0.0162\n",
      "Epoch 5/30\n",
      "1603/1603 [==============================] - 8s 5ms/step - loss: 0.0162\n",
      "Epoch 6/30\n",
      "1603/1603 [==============================] - 9s 5ms/step - loss: 0.0162\n",
      "Epoch 7/30\n",
      "1603/1603 [==============================] - 9s 5ms/step - loss: 0.0162\n",
      "Epoch 8/30\n",
      "1603/1603 [==============================] - 9s 6ms/step - loss: 0.0162\n",
      "Epoch 9/30\n",
      "1603/1603 [==============================] - 10s 6ms/step - loss: 0.0162\n",
      "Epoch 10/30\n",
      "1603/1603 [==============================] - 9s 5ms/step - loss: 0.0161\n",
      "Epoch 11/30\n",
      "1603/1603 [==============================] - 9s 5ms/step - loss: 0.0161\n",
      "Epoch 12/30\n",
      "1603/1603 [==============================] - 9s 5ms/step - loss: 0.0161\n",
      "Epoch 13/30\n",
      "1603/1603 [==============================] - 8s 5ms/step - loss: 0.0161\n",
      "Epoch 14/30\n",
      "1603/1603 [==============================] - 8s 5ms/step - loss: 0.0161\n",
      "Epoch 15/30\n",
      "1603/1603 [==============================] - 8s 5ms/step - loss: 0.0161\n",
      "Epoch 16/30\n",
      "1603/1603 [==============================] - 8s 5ms/step - loss: 0.0161\n",
      "Epoch 17/30\n",
      "1603/1603 [==============================] - 8s 5ms/step - loss: 0.0161\n",
      "Epoch 18/30\n",
      "1603/1603 [==============================] - 8s 5ms/step - loss: 0.0161\n",
      "Epoch 19/30\n",
      "1603/1603 [==============================] - 9s 5ms/step - loss: 0.0161\n",
      "Epoch 20/30\n",
      "1603/1603 [==============================] - 8s 5ms/step - loss: 0.0161\n",
      "Epoch 21/30\n",
      "1603/1603 [==============================] - 8s 5ms/step - loss: 0.0161\n",
      "Epoch 22/30\n",
      "1603/1603 [==============================] - 8s 5ms/step - loss: 0.0161\n",
      "Epoch 23/30\n",
      "1603/1603 [==============================] - 8s 5ms/step - loss: 0.0161A: 2\n",
      "Epoch 24/30\n",
      "1603/1603 [==============================] - 8s 5ms/step - loss: 0.0161\n",
      "Epoch 25/30\n",
      "1603/1603 [==============================] - 8s 5ms/step - loss: 0.0161A: 0s - loss: 0\n",
      "Epoch 26/30\n",
      "1603/1603 [==============================] - 8s 5ms/step - loss: 0.0161\n",
      "Epoch 27/30\n",
      "1603/1603 [==============================] - 8s 5ms/step - loss: 0.0161\n",
      "Epoch 28/30\n",
      "1603/1603 [==============================] - 9s 6ms/step - loss: 0.0161\n",
      "Epoch 29/30\n",
      "1603/1603 [==============================] - 9s 6ms/step - loss: 0.0160\n",
      "Epoch 30/30\n",
      "1603/1603 [==============================] - 9s 5ms/step - loss: 0.0160\n",
      "Training accuracy:  0.8816431690580162\n",
      "Test:  0.883225\n",
      "========================================================================================================\n",
      "========================================================================================================\n",
      "KFOLD:  4\n",
      "Test: 1600 2000\n",
      "Train: [ 0 1600 ] [ 2000 2003 ]\n",
      "Epoch 1/30\n",
      "1603/1603 [==============================] - 9s 6ms/step - loss: 0.0162\n",
      "Epoch 2/30\n",
      "1603/1603 [==============================] - 9s 6ms/step - loss: 0.0162\n",
      "Epoch 3/30\n",
      "1603/1603 [==============================] - 9s 6ms/step - loss: 0.0162\n",
      "Epoch 4/30\n",
      "1603/1603 [==============================] - 9s 5ms/step - loss: 0.0162\n",
      "Epoch 5/30\n",
      "1603/1603 [==============================] - 9s 6ms/step - loss: 0.0162\n",
      "Epoch 6/30\n",
      "1603/1603 [==============================] - 9s 6ms/step - loss: 0.0162\n",
      "Epoch 7/30\n",
      "1603/1603 [==============================] - 9s 5ms/step - loss: 0.0162\n",
      "Epoch 8/30\n",
      "1603/1603 [==============================] - 9s 6ms/step - loss: 0.0161\n",
      "Epoch 9/30\n",
      "1603/1603 [==============================] - 9s 6ms/step - loss: 0.0161\n",
      "Epoch 10/30\n",
      "1603/1603 [==============================] - 9s 6ms/step - loss: 0.0161\n",
      "Epoch 11/30\n",
      "1603/1603 [==============================] - 9s 5ms/step - loss: 0.0161\n",
      "Epoch 12/30\n",
      "1603/1603 [==============================] - 9s 5ms/step - loss: 0.0161\n",
      "Epoch 13/30\n",
      "1603/1603 [==============================] - 9s 6ms/step - loss: 0.0161\n",
      "Epoch 14/30\n",
      "1603/1603 [==============================] - 9s 6ms/step - loss: 0.0161\n",
      "Epoch 15/30\n",
      "1603/1603 [==============================] - 9s 6ms/step - loss: 0.0161\n",
      "Epoch 16/30\n",
      "1603/1603 [==============================] - 9s 5ms/step - loss: 0.0161\n",
      "Epoch 17/30\n",
      "1603/1603 [==============================] - 9s 6ms/step - loss: 0.0161\n",
      "Epoch 18/30\n",
      "1603/1603 [==============================] - 9s 6ms/step - loss: 0.0161\n",
      "Epoch 19/30\n",
      "1603/1603 [==============================] - 9s 6ms/step - loss: 0.0161\n",
      "Epoch 20/30\n",
      "1603/1603 [==============================] - 9s 6ms/step - loss: 0.0161\n",
      "Epoch 21/30\n",
      "1603/1603 [==============================] - 9s 6ms/step - loss: 0.0161\n",
      "Epoch 22/30\n",
      "1603/1603 [==============================] - 9s 5ms/step - loss: 0.0161\n",
      "Epoch 23/30\n",
      "1603/1603 [==============================] - 9s 6ms/step - loss: 0.0161\n",
      "Epoch 24/30\n",
      "1603/1603 [==============================] - 9s 5ms/step - loss: 0.0160\n",
      "Epoch 25/30\n",
      "1603/1603 [==============================] - 9s 5ms/step - loss: 0.0160\n",
      "Epoch 26/30\n",
      "1603/1603 [==============================] - 9s 5ms/step - loss: 0.0160A: 0s - loss: 0.\n",
      "Epoch 27/30\n",
      "1603/1603 [==============================] - 9s 5ms/step - loss: 0.0160\n",
      "Epoch 28/30\n",
      "1603/1603 [==============================] - 10s 6ms/step - loss: 0.0160\n",
      "Epoch 29/30\n",
      "1603/1603 [==============================] - 9s 6ms/step - loss: 0.0160\n",
      "Epoch 30/30\n",
      "1603/1603 [==============================] - 9s 5ms/step - loss: 0.0160\n",
      "Training accuracy:  0.8812326887086712\n",
      "Test:  0.886035\n",
      "========================================================================================================\n"
     ]
    }
   ],
   "source": [
    "kFolds = 5\n",
    "kFoldAccuracy = []\n",
    "split_value = int((1/kFolds)*Xtr_10k.shape[0])\n",
    "for fold in range(kFolds):\n",
    "    Testfrom = fold*split_value\n",
    "    Testto = (fold+1)*split_value\n",
    "    \n",
    "    Trainto1 = (fold)*split_value    \n",
    "    Trainfrom2 = (fold+1)*split_value\n",
    "    print (\"========================================================================================================\")\n",
    "    print (\"KFOLD: \",fold)\n",
    "    print (\"Test:\", Testfrom,Testto)\n",
    "    print (\"Train: [\",0,Trainto1,\"] [\",Testto,Xtr_10k.shape[0],\"]\")\n",
    "    \n",
    "    X_train = ((np.concatenate((Xtr_10k[:Trainto1],Xtr_10k[Trainfrom2:])))).astype('float')\n",
    "    X_ts = (Xtr_10k[Testfrom:Testto]).astype('float')\n",
    "\n",
    "    y_train = ((np.concatenate((ytr_10k[:Trainto1],ytr_10k[Trainfrom2:])))/2).astype('float')\n",
    "    y_ts = (ytr_10k[Testfrom:Testto]).astype('float')\n",
    "    reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5,\n",
    "                              patience=3, min_lr=0.00001)\n",
    "    model_10k.fit(X_train, y_train, epochs=30, verbose=1,callbacks=[reduce_lr])\n",
    "    a=Accuracy(X_train,y_train,model_10k)\n",
    "    aprime=Accuracy(X_ts,y_ts,model_10k)\n",
    "    print (\"Training accuracy: \", np.mean(a))\n",
    "    print (\"Test: \", np.mean(aprime))\n",
    "    kFoldAccuracy.append(np.mean(aprime))\n",
    "    print (\"========================================================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.850934131736527"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy(Xts_10k,yts_10k,model_10k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.882191712431353"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy(Xtr_10k,ytr_10k,model_10k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Layers_10k = model_10k.layers\n",
    "W_10k,b_10k = Layers_10k[0].get_weights()\n",
    "W_10k[W_10k==-0.0]=0.0\n",
    "b_10k[b_10k==-0.0]=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_10k = (W_10k*10000).astype('int')\n",
    "b_10k = (b_10k*10000).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros = ((W_10k.shape[0]*W_10k.shape[1])-(np.count_nonzero(W_10k)))/(W_10k.shape[0]*W_10k.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23891270600744285"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(W_10k)/(3135*1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3135, 1500)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_10k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('W_10k_complete.txt', W_10k, delimiter=',',fmt='%1.4f') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Layers_10k = model_10k.layers\n",
    "W_10k,b_10k = Layers_10k[0].get_weights()\n",
    "W_10k[W_10k==-0.0]=0.0\n",
    "b_10k[b_10k==-0.0]=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b[b==-0.0]=0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('W_10k_complete.txt', W_10k, delimiter=',',fmt='%1.4f') \n",
    "np.savetxt('b_10k_complete.txt', b_10k, delimiter=',',fmt='%1.4f') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = model_10k.predict(Xts_10k)\n",
    "yts_10k_hat = np.argmax((y1.reshape((y1.shape[0],int(y1.shape[1]/3),3))),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "O = np.dot(Xts_10k,W)+b\n",
    "O_num = np.argmax((O.reshape((O.shape[0],int(O.shape[1]/3),3))),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for u in O_num==yts_10k_hat:\n",
    "    print (True in u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(Matrix):\n",
    "    min_value = np.min(Matrix)\n",
    "    max_value = np.max(Matrix)\n",
    "    ScaledMatrix = (Matrix-min_value)/(max_value-min_value)\n",
    "    return (ScaledMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yts_hat_normalized = scale(model.predict(Xts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = yts_hat_normalized.reshape((500,500,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divs = np.array([np.sum(i,1) for i in temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yts_preds = np.zeros((temp.shape))\n",
    "for i in range(500):\n",
    "    for j in range(500):\n",
    "        yts_preds[i][j] = temp[i][j]/divs[i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp2 = yts_preds.reshape((250000,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yts_print = yts.reshape((500,500,3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('y_pred.txt', temp2, delimiter=',',fmt='%1.6f') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('y_actual.txt', yts1.astype('int').reshape((250000,1)), delimiter=',',fmt='%1d') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homomorphic part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.loadtxt('W.txt',delimiter=',')\n",
    "b = np.loadtxt('b.txt',delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "np.dot(Xts,W)+b\n",
    "print (\"Time required in plain-text\",time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phe import paillier\n",
    "puk, prk = paillier.generate_paillier_keypair(n_length=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xts_10k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "Xts_e = EncryptVector(puk,Xts)\n",
    "print (time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtemp1 = Xts.reshape((500*3135,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool.apply([puk.encrypt(i) for i in range(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "pool = mp.Pool(mp.cpu_count())\n",
    "start_time = time.time()\n",
    "Xts_e1 = pool.apply(EncryptVector(puk,a))\n",
    "print (time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EncryptVector(pubkey, x):\n",
    "    xtemp = x.reshape((x.shape[0]*x.shape[1],1))\n",
    "    return (np.array([pubkey.encrypt(xtemp[i][0]) for i in range(xtemp.shape[0])])).reshape(x.shape)\n",
    "\n",
    "def DecryptVector(privkey, x):\n",
    "    xtemp = x.reshape((x.shape[0]*x.shape[1],1))\n",
    "    return (np.array([privkey.decrypt(i[0]) for i in xtemp])).reshape(x.shape)\n",
    "\n",
    "def AddEncryptedVectors(x, y):\n",
    "\n",
    "    if len(x) != len(y):\n",
    "        raise Exception('Encrypted vectors must have the same size')\n",
    "\n",
    "    return [x[i] + y[i] for i in range(len(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "Xts_e = EncryptVector(puk,Xts)\n",
    "print (time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "d = b+c_e\n",
    "print (time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Check_Xts = DecryptVector(prk,Xts_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = np.ones((10,3135))\n",
    "t2 = np.ones((3135,1500))\n",
    "t1_e = EncryptVector(puk,t1)\n",
    "#t2_e = EncryptVector(puk,t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "m_e = np.dot(t1_e,t2)\n",
    "print (time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "m_e = np.dot(t1_e,t2)\n",
    "print (time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = DecryptVector(prk,m_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (np.ones((500,1500)))*1.32\n",
    "b = (np.ones((500,1500)))*2.32\n",
    "start_time = time.time()\n",
    "Xts_e = EncryptVector(puk,Xts)\n",
    "print (time.time()-start_time)\n",
    "#b_e = EncryptVector(puk,b)\n",
    "#c_e = a_e + b\n",
    "#c = DecryptVector(c_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "Xts_e.dot(W)\n",
    "print (time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = DecryptVector(prk,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def decrypt_vector(privkey, x):\n",
    "    return np.array([privkey.decrypt(i) for i in x])\n",
    "\n",
    "\n",
    "def sum_encrypted_vectors(x, y):\n",
    "\n",
    "    if len(x) != len(y):\n",
    "        raise Exception('Encrypted vectors must have the same size')\n",
    "\n",
    "    return [x[i] + y[i] for i in range(len(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EncXts = []\n",
    "for i in range(Xts.shape[0]):\n",
    "    for j in range(Xts.shape[1]):\n",
    "        #print (i,j)\n",
    "        EncXts[i][j]=(puk.encrypt(Xts[i][j])).ciphertext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EncXts2 = []\n",
    "for i in range(Xts.shape[0]):\n",
    "    for j in range(Xts.shape[1]):\n",
    "        #print (i,j)\n",
    "        EncXts2.append(puk.encrypt(Xts[i][j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EncXts2 = np.array(EncXts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EncXts2 = EncXts2.reshape((Xts.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[9,5],[2,5],[1,7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array([[puk.encrypt(6)],[puk.encrypt(11)]])\n",
    "d = np.array([[6],[11]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = np.array([[puk.encrypt(8)],[puk.encrypt(1)]])\n",
    "g = np.array([[8],[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MatMul(A,B):\n",
    "    ResultsTemp = []\n",
    "    for i in range(A.shape[0]):\n",
    "        #print (i)\n",
    "        for j in range(B.shape[1]):\n",
    "            temp = 0\n",
    "            for k in range(B.shape[0]):\n",
    "                temp += A[i][k] * B[k][j]\n",
    "            ResultsTemp.append(temp)\n",
    "    ResultsTemp = np.array(ResultsTemp)\n",
    "    Results = ResultsTemp.reshape((A.shape[0],B.shape[1]))\n",
    "    return (Results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = b+f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "e = MatMul(a,b)\n",
    "print (\"Time required to multiply\",time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in z:\n",
    "    print (prk.decrypt(i[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "O = np.argmax((np.matmul(Xts,W)+b).reshape((504,500,3)),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "O2 = np.argmax((model.predict(Xts)).reshape((504,500,3)),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero((O!=O2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('W_10k.txt', W, delimiter=',') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('b_10k.txt',b,delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(Matrix):\n",
    "    min_value = np.min(Matrix)\n",
    "    max_value = np.max(Matrix)\n",
    "    ScaledMatrix = (Matrix-min_value)/(max_value-min_value)\n",
    "    return (ScaledMatrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
